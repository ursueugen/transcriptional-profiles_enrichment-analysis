{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSEA\n",
    "\n",
    "Using `GSEApy` I perform GSEA for cluster 1 and 2 from the systems aging study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gseapy as gp\n",
    "from gseapy import Biomart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_c1.shape=(1243, 4) | df_c2.shape=(547, 4)\n"
     ]
    }
   ],
   "source": [
    "read_supp_table_3 = lambda sheet: pd.read_excel(\n",
    "    \"data/Supplementary Table 3.xlsx\", \n",
    "    sheet_name=sheet,\n",
    "    )\n",
    "\n",
    "df_c1_up = read_supp_table_3(\"Cluster 1 - upregulated \")\n",
    "df_c1_down = read_supp_table_3(\"Cluster 1 - downregulated\")\n",
    "df_c2_up = read_supp_table_3(\"Cluster 2 - upregulated\")\n",
    "df_c2_down = read_supp_table_3(\"Cluster 2 - downregulated\")\n",
    "\n",
    "df_c1_up[\"logFC\"] = df_c1_up[\"max(|logFC|)\"]\n",
    "df_c1_down[\"logFC\"] = - df_c1_down[\"max(|logFC|)\"]\n",
    "df_c1 = pd.concat([df_c1_up, df_c1_down]).rename(columns={\"ENTREZ\": \"entrezgene_id\"})\n",
    "\n",
    "df_c2_up[\"logFC\"] = df_c2_up[\"max(|logFC|)\"]\n",
    "df_c2_down[\"logFC\"] = - df_c2_down[\"max(|logFC|)\"]\n",
    "df_c2 = pd.concat([df_c2_up, df_c2_down]).rename(columns={\"ENTREZ\": \"entrezgene_id\"})\n",
    "\n",
    "del df_c1_up, df_c1_down, df_c2_up, df_c2_down\n",
    "print(f\"{df_c1.shape=} | {df_c2.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_c1[\"entrezgene_id\"].isna().sum() == 0\n",
    "assert df_c2[\"entrezgene_id\"].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for GSEApy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(entrez_ids)=1682\n"
     ]
    }
   ],
   "source": [
    "entrez_ids = df_c1[\"entrezgene_id\"].tolist() + df_c2[\"entrezgene_id\"].tolist()\n",
    "entrez_ids = list(set(entrez_ids))\n",
    "print(f\"{len(entrez_ids)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>external_gene_name</th>\n",
       "      <th>entrezgene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000236362</td>\n",
       "      <td>GAGE12F</td>\n",
       "      <td>100008586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000200394</td>\n",
       "      <td>SNORA38B</td>\n",
       "      <td>100124536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ensembl_gene_id external_gene_name  entrezgene_id\n",
       "0  ENSG00000236362            GAGE12F      100008586\n",
       "1  ENSG00000200394           SNORA38B      100124536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split in 2 queries not to exceed the limit\n",
    "bm = Biomart()\n",
    "\n",
    "queries_1 = {\n",
    "    'entrezgene_id': entrez_ids[:800],\n",
    "}\n",
    "queries_2 = {\n",
    "    'entrezgene_id': entrez_ids[800:],\n",
    "}\n",
    "\n",
    "results_1 = bm.query(dataset='hsapiens_gene_ensembl',\n",
    "                   attributes=['ensembl_gene_id', 'external_gene_name', 'entrezgene_id'],\n",
    "                   filters=queries_1)\n",
    "results_2 = bm.query(dataset='hsapiens_gene_ensembl',\n",
    "                   attributes=['ensembl_gene_id', 'external_gene_name', 'entrezgene_id'],\n",
    "                   filters=queries_2)\n",
    "        \n",
    "gene_ids_map = pd.concat([results_1, results_2])\n",
    "gene_ids_map = gene_ids_map.dropna(axis=0)\n",
    "assert gene_ids_map[\"entrezgene_id\"].isna().sum() == 0\n",
    "gene_ids_map.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_c1.shape=(1393, 6) | df_c2.shape=(601, 6)\n"
     ]
    }
   ],
   "source": [
    "df_c1 = pd.merge(df_c1, gene_ids_map, on=\"entrezgene_id\", how=\"left\")\n",
    "df_c2 = pd.merge(df_c2, gene_ids_map, on=\"entrezgene_id\", how=\"left\")\n",
    "\n",
    "df_c1.to_csv(\"data/df_c1.tsv\", sep='\\t', index=False)\n",
    "df_c2.to_csv(\"data/df_c2.tsv\", sep='\\t', index=False)\n",
    "\n",
    "print(f\"{df_c1.shape=} | {df_c2.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(df_c1.groupby(\"external_gene_name\")[\"logFC\"].nunique() == 1), \"All external gene names have same logFC\"\n",
    "assert all(df_c2.groupby(\"external_gene_name\")[\"logFC\"].nunique() == 1), \"All external gene names have same logFC\"\n",
    "\n",
    "c1_rnk = pd.DataFrame(df_c1.groupby(\"external_gene_name\")[\"logFC\"].mean()).sort_values(\"logFC\", ascending=False)\n",
    "c2_rnk = pd.DataFrame(df_c2.groupby(\"external_gene_name\")[\"logFC\"].mean()).sort_values(\"logFC\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run GSEApy Prerank\n",
    "\n",
    "- We use this approach because we operate on a ranked, metric list of genes, and not the classical GSEA scenario of many samples per conditions, 2 conditions.\n",
    "- Gene set names come from [Enrichr libraries](https://maayanlab.cloud/Enrichr/#libraries).\n",
    "- Takes about 6 mins to run on laptop for C1\n",
    "- Tag% - % gene hits (in filtered gene set) before (ES>0) or after (ES<0) peak in running ES score. Gives an indication of percentage of genes contributing to the ES.\n",
    "- Gene% - % genes in the ranked list before (ES>0) or after (ES<0) the peak in the running ES. Indicates where in the list the ES is attained.\n",
    "- to include GO and smaller sets, we do another analysis where we don't limit `min_size` to 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(GENE_SETS)=4\n"
     ]
    }
   ],
   "source": [
    "GENE_SETS = [\n",
    "    'KEGG_2021_Human', \n",
    "    'GO_Biological_Process_2021'\n",
    "    'MSigDB_Hallmark_2020',\n",
    "    'Reactome_2022',\n",
    "    'ChEA_2022',\n",
    "]\n",
    "print(f\"{len(GENE_SETS)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prerank_analysis(\n",
    "    data, \n",
    "    gene_sets, \n",
    "    outdir, \n",
    "    min_set_size = 5\n",
    "    ):\n",
    "    res = gp.prerank(\n",
    "        rnk=data,\n",
    "        gene_sets=gene_sets,\n",
    "        threads=4,\n",
    "        min_size=min_set_size,\n",
    "        max_size=1000,\n",
    "        permutation_num=1000,\n",
    "        outdir=outdir,\n",
    "        seed=42,\n",
    "        verbose=False\n",
    "        )\n",
    "    return res\n",
    "\n",
    "\n",
    "def process_results(analysis_results, outdir) -> pd.DataFrame:\n",
    "    df_res = analysis_results.res2d.copy()\n",
    "    df_res[\"Gene_set\"] = df_res[\"Term\"].str.split(\"__\").str[0]\n",
    "    df_res[\"Term_clean\"] = df_res[\"Term\"].str.split(\"__\").str[1]\n",
    "\n",
    "    for head_N in [10, 30]:\n",
    "        df_res.groupby(\"Gene_set\").head(head_N).to_csv(f\"{outdir}/head-{head_N}_by_geneset.tsv\", sep='\\t')\n",
    "\n",
    "    df_res.to_csv(f\"{outdir}/processed.tsv\", sep='\\t')\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 19:42:21,588 No supported gene_sets: GO_Biological_Process_2021MSigDB_Hallmark_2020\n"
     ]
    }
   ],
   "source": [
    "pre_res_c1 = run_prerank_analysis(c1_rnk, GENE_SETS, \"results/prerank_c1\")\n",
    "df_res_c1 = process_results(pre_res_c1, \"results/prerank_c1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1 Biological Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_res_c1_go = run_prerank_analysis(c1_rnk, [\"GO_Biological_Process_2021\"], \"results/prerank_c1_go\", 1)\n",
    "df_c1_go = process_results(pre_res_c1_go, \"results/prerank_c1_go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 19:43:49,186 No supported gene_sets: GO_Biological_Process_2021MSigDB_Hallmark_2020\n"
     ]
    }
   ],
   "source": [
    "pre_res_c2 = run_prerank_analysis(c2_rnk, GENE_SETS, \"results/prerank_c2\")\n",
    "df_c2 = process_results(pre_res_c2, \"results/prerank_c2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C2 Biological Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_res_c2_go = run_prerank_analysis(c2_rnk, [\"GO_Biological_Process_2021\"], \"results/prerank_c2_go\", 1)\n",
    "df_c2_go = process_results(pre_res_c2_go, \"results/prerank_c2_go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare table with all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_1    5089\n",
       "cluster_2    3491\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c1[\"cluster\"] = \"cluster_1\"\n",
    "df_c1_go[\"cluster\"] = \"cluster_1\"\n",
    "df_c2[\"cluster\"] = \"cluster_2\"\n",
    "df_c2_go[\"cluster\"] = \"cluster_2\"\n",
    "\n",
    "df_full = pd.concat([df_c1, df_c1_go, df_c2, df_c2_go], axis=0)\n",
    "df_full[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_full[[\n",
    "        \"cluster\", \"entrezgene_id\", \"external_gene_name\", \"Number of datasets\", \"max(|logFC|)\", \"logFC\",\n",
    "        \"Term\", \"ES\", \"NES\", \"NOM p-val\", \"FDR q-val\", \"FWER p-val\", \"Tag %\", \"Gene %\", \"Lead_genes\",\n",
    "    ]].to_csv(\"results/Supp_Table4.tsv\", sep='\\t', index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ds_stack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a0bb66b70420c9f067386cae2a09278e8c21c89d1aad58cbb037b9135901ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
